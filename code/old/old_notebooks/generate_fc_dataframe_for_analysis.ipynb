{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 01.09.2025\n",
    "### Task description for Emily: creating master dataframe for BOLD functional connectivity analysis"
   ]
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:37:46.756327Z",
     "start_time": "2025-01-13T14:37:37.166108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from nilearn import input_data, datasets\n",
    "import os\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T14:42:03.731979Z",
     "start_time": "2025-01-13T14:42:03.723042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## If this is set to true, then the notebook will attempt to generate a giant data structure containing\n",
    "## all the time series for all the subjects and conditions and voxels. This is a very large data structure\n",
    "generate_time_series = False\n",
    "\n",
    "# data_root is only used if generate_time_series is set to True\n",
    "data_root = '/Users/jacekdmochowski/PROJECTS/fus/data/resampled_bold_flywheel/'\n",
    "\n",
    "# if you change these, you straight trippin\n",
    "idx_pre = range(60,300) # we start at 60 instead of 0 because of some strange artifact at the beginning of the time series\n",
    "idx_fus = range(300,600)\n",
    "idx_post = range(600,900)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:41:06.569975Z",
     "start_time": "2025-01-13T15:41:06.534291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load DiFuMo atlas\n",
    "difumo = datasets.fetch_atlas_difumo(dimension=1024)\n",
    "labels = difumo.labels  # List of 1024 anatomical labels\n",
    "labels = pd.DataFrame(labels) # cast to dataframe to allow call to itertuples below\n",
    "atlas_img = nib.load(difumo.maps)\n",
    "# Dataframe loaded in differently than in the notebook, got key error when trying to access labels[0][1]. Altered the code to match output in notebook.\n",
    "print(f'Old: {labels[:3]}\\n')\n",
    "#print(labels[:3]['difumo_names'])\n",
    "#print(labels[:3]['difumo_names'][0])\n",
    "labels = list(labels.itertuples(index=False, name=None))\n",
    "print(f'New: {labels[:3]}\\n')\n",
    "\n",
    "#Print out the labels of the first 5 regions of interest\n",
    "for i in range(5):\n",
    "    print(f'\\n{labels[i][1]}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old:    component                                       difumo_names  \\\n",
      "0          1                           Retrocalcarine cortex RH   \n",
      "1          2  Superior longitudinal fasciculus II mid-poster...   \n",
      "2          3                 Arcuate fasciculus mid-anterior RH   \n",
      "\n",
      "      yeo_networks7    yeo_networks17        gm        wm       csf  \n",
      "0           VisCent           VisCent  0.448141  0.536476  0.015397  \n",
      "1  No network found  No network found  0.017326  0.982661  0.000024  \n",
      "2         DorsAttnB             ContA  0.502915  0.473717  0.023376  \n",
      "\n",
      "New: [(1, 'Retrocalcarine cortex RH', 'VisCent', 'VisCent', 0.4481405353262207, 0.5364755823378832, 0.0153973010223141), (2, 'Superior longitudinal fasciculus II mid-posterior RH', 'No network found', 'No network found', 0.0173264119360224, 0.982661041962447, 2.3660546855248283e-05), (3, 'Arcuate fasciculus mid-anterior RH', 'DorsAttnB', 'ContA', 0.5029148769880778, 0.4737174507005034, 0.0233761400386116)]\n",
      "\n",
      "\n",
      "Retrocalcarine cortex RH\n",
      "\n",
      "Superior longitudinal fasciculus II mid-posterior RH\n",
      "\n",
      "Arcuate fasciculus mid-anterior RH\n",
      "\n",
      "Cerebrospinal fluid (between middle frontal gyrus anterior and skull)\n",
      "\n",
      "Precentral sulcus mid-inferior RH\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T17:43:40.741072Z",
     "start_time": "2025-01-10T17:43:40.735010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_folders(path):\n",
    "    \"\"\"Gets all folders within a specified path.\"\"\"\n",
    "    folders = []\n",
    "    for entry in os.scandir(path):\n",
    "        if entry.is_dir():\n",
    "            folders.append(entry.name)\n",
    "    return folders"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:53.554297Z",
     "start_time": "2025-01-09T18:32:53.548582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_prepare_data(bold_files, confounds_files, difumo_atlas):\n",
    "    \"\"\"\n",
    "    Load and prepare BOLD data using the DiFuMo probabilistic atlas\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    bold_files : list of str\n",
    "        Paths to preprocessed BOLD data for each subject/session\n",
    "    confounds_files : list of str\n",
    "        Paths to confound regressors from fMRIprep\n",
    "    difumo_atlas : str or NiftiImage\n",
    "        Path to DiFuMo probabilistic atlas or loaded atlas image\n",
    "    target_roi_indices : list of int\n",
    "        Indices of ROIs in target region (subgenual ACC)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    time_series_dict : dict\n",
    "        Dictionary containing cleaned time series for each subject/condition\n",
    "    \"\"\"\n",
    "    # Use NiftiMapsMasker instead of NiftiLabelsMasker for probabilistic atlas\n",
    "    masker = input_data.NiftiMapsMasker(\n",
    "        maps_img=difumo_atlas,\n",
    "        standardize=True,\n",
    "        detrend=False,\n",
    "        low_pass=0.1,\n",
    "        high_pass=0.01,\n",
    "        t_r=1.0,\n",
    "        memory='nilearn_cache',  # Cache computations\n",
    "        memory_level=1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    time_series_dict = {\n",
    "        'active': [],\n",
    "        'sham': []\n",
    "    }\n",
    "\n",
    "    for bold_file, confound_file in zip(bold_files, confounds_files):\n",
    "        # Load confounds\n",
    "        confounds = pd.read_csv(confound_file, sep='\\t')\n",
    "\n",
    "        # Select specific confound regressors\n",
    "        selected_confounds = pd.concat([\n",
    "            # Motion parameters and their derivatives/quadratic terms\n",
    "            #confounds.filter(regex='^(trans|rot)_(x|y|z)($|_derivative1$|_power2$)'),\n",
    "            confounds.filter(regex='^(trans|rot)_(x|y|z)($|_derivative1$)'),\n",
    "\n",
    "            # CompCor components\n",
    "            #confounds.filter(regex='^[at]_comp_cor_\\d+'),\n",
    "\n",
    "            # Global signals\n",
    "            #confounds[['csf', 'white_matter', 'global_signal']],\n",
    "\n",
    "            # Motion outliers\n",
    "            #confounds.filter(regex='^motion_outlier'),\n",
    "\n",
    "            # Edge/crown signals\n",
    "            #confounds.filter(regex='^edge_')\n",
    "        ], axis=1)\n",
    "\n",
    "        # remove any columns in selected_confounds that have nans\n",
    "        selected_confounds = selected_confounds.dropna(axis=1)\n",
    "\n",
    "        # Extract time series with confound regression\n",
    "        # This will now return time series for each probabilistic component\n",
    "        time_series = masker.fit_transform(bold_file, confounds=selected_confounds)\n",
    "\n",
    "        # Sort into conditions\n",
    "        if 'ACTIVE' in bold_file:\n",
    "            time_series_dict['active'].append(time_series)\n",
    "        else:\n",
    "            time_series_dict['sham'].append(time_series)\n",
    "\n",
    "    return time_series_dict"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:54.391163Z",
     "start_time": "2025-01-09T18:32:54.386433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_difumo_atlas(atlas_path):\n",
    "    \"\"\"\n",
    "    Load DiFuMo atlas and verify its dimensions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    atlas_path : str\n",
    "        Path to the DiFuMo atlas file\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    atlas_img : Nifti1Image\n",
    "        Loaded atlas image\n",
    "    \"\"\"\n",
    "    from nilearn import image\n",
    "\n",
    "    atlas_img = image.load_img(atlas_path)\n",
    "\n",
    "    # Verify this is a 4D image with 1024 components\n",
    "    if atlas_img.ndim != 4:\n",
    "        raise ValueError(\"Expected 4D atlas image\")\n",
    "    if atlas_img.shape[-1] != 1024:\n",
    "        raise ValueError(f\"Expected 1024 components, got {atlas_img.shape[-1]}\")\n",
    "\n",
    "    return atlas_img"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:55.452292Z",
     "start_time": "2025-01-09T18:32:55.446758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if generate_time_series:\n",
    "    ## Generate a list of all available bold records from both ACTIVE and SHAM sessions\n",
    "    \n",
    "    # list all folders in data_root\n",
    "    folders = [f for f in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, f))]\n",
    "    bold_files = []\n",
    "    confounds_files = []\n",
    "    for folder in folders:\n",
    "        # find file in output_folder that contains 'preproc_bold_resampled'\n",
    "        output_folder = os.listdir(os.path.join(os.path.join(data_root,folder),'output'))\n",
    "        for file in output_folder:\n",
    "            if 'preproc_bold_resampled' in file:\n",
    "                bold_files.append(os.path.join(os.path.join(data_root,folder),'output',file))\n",
    "    \n",
    "        # confounds timeseries\n",
    "        input_folder=os.path.join(os.path.join(data_root,folder),'input')\n",
    "        tmp=get_folders(os.path.join(os.path.join(data_root,folder),'input'))[0]\n",
    "        tmp2=[x for x in get_folders(os.path.join(input_folder,tmp)) if 'sub-' in x]\n",
    "        tmp3=os.path.join(os.path.join(input_folder,tmp),tmp2[0])\n",
    "        tmp4=[os.path.join(tmp3,x) for x in os.listdir(tmp3) if 'ses-' in x][0]\n",
    "        tmp5=[os.path.join(tmp4,x) for x in os.listdir(tmp4) if 'func' in x][0]\n",
    "        confounds_files.append([os.path.join(tmp5,x) for x in os.listdir(tmp5) if 'confounds_timeseries.tsv' in x][0])\n",
    "    \n",
    "    print(f\"Found {len(bold_files)} bold files\")\n",
    "    print(f\"Found {len(confounds_files)} confounds files\")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:56.487598Z",
     "start_time": "2025-01-09T18:32:56.483919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if generate_time_series:\n",
    "    path_to_difumo = '/Users/jacekdmochowski/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_atlas-DiFuMo_desc-1024dimensions_probseg.nii.gz'\n",
    "    try:\n",
    "        difumo_atlas = load_difumo_atlas(path_to_difumo)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error loading DiFuMo atlas: {e}\")\n",
    "        print(\"Attempting to download from TemplateFlow\")\n",
    "        if path_to_difumo is None:\n",
    "            path_to_difumo = api.get('MNI152NLin2009cAsym', atlas=\"DiFuMo\", desc=\"1024dimensions\", resolution=2, suffix=\"probseg\", extension=\"nii.gz\")\n",
    "        difumo_atlas = nib.load(path_to_difumo)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:43:08.812754Z",
     "start_time": "2025-01-13T14:43:08.672227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if generate_time_series:\n",
    "    time_series = load_and_prepare_data(bold_files, confounds_files, difumo_atlas)\n",
    "    with open('../data/precomputed/difumo_time_series.pkl', 'wb') as f:\n",
    "        pickle.dump(time_series, f)\n",
    "else:\n",
    "    with open('../data/precomputed/difumo_time_series.pkl', 'rb') as f:\n",
    "        time_series = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Let's take a look at the data, shall we ?!  Yeeaaahhh"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T14:43:12.638348Z",
     "start_time": "2025-01-13T14:43:12.630216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(time_series.keys())\n",
    "print(type(time_series['active']),len(time_series['active']))\n",
    "print(time_series['active'][0].shape) # 900 TRs, 1024 brain regions, yeaaaah"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['active', 'sham'])\n",
      "<class 'list'> 16\n",
      "(900, 1024)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T14:43:16.716594Z",
     "start_time": "2025-01-13T14:43:16.625171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bold_3d_active = np.array(time_series['active'])\n",
    "bold_3d_sham = np.array(time_series['sham'])\n",
    "#16 rows for 16 subjects, 900 columns for 900 TRs (time) and 1024 elements in a list for each time point (brain regions)\n",
    "print(bold_3d_active.shape, bold_3d_sham.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 900, 1024) (16, 900, 1024)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initialize pandas dataframe that will store all functional connectivity values"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T14:43:20.904655Z",
     "start_time": "2025-01-13T14:43:20.895699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(columns=['fc', 'roi1', 'roi2', 'subject', 'time_window', 'condition'])\n",
    "# subject is a number from 0 to 15\n",
    "# roi is a number from 0 to 1023\n",
    "# only unique pairs of rois should be added (0,1), (0,2), ...  NOT (0,1) and (1,0)\n",
    "# condition is either active or sham\n",
    "# time_window is either pre, fus, or post\n",
    "# fc is a floating point value"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Demonstrate how to compute functional connectivity for one row of the matrix"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:38:57.234266Z",
     "start_time": "2025-01-13T15:38:57.165199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subject_idx = 0 # note: we never correlate between subjects\n",
    "roi1 = 0 # zero based indexing!\n",
    "roi2 = 1\n",
    "time_segment = idx_pre\n",
    "\n",
    "this_bold = bold_3d_active[subject_idx,time_segment,:] # the bold of this subject\n",
    "print(this_bold.shape)\n",
    "\n",
    "corrmat = np.corrcoef(this_bold.T) # this is called a correlation matrix\n",
    "print(corrmat.shape)\n",
    "#print(f'Original Array: {corrmat}')\n",
    "\n",
    "print(f'New Array: {np.triu(corrmat, 1)}')\n",
    "\n",
    "corrmat = np.triu(corrmat, 1)\n",
    "\n",
    "indices = np.triu_indices(corrmat.shape[0], 1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 1024)\n",
      "(1024, 1024)\n",
      "New Array: [[ 0.          0.39281545  0.62921009 ...  0.04781121  0.07901669\n",
      "   0.21152004]\n",
      " [ 0.          0.          0.21432748 ...  0.35306738  0.2891584\n",
      "   0.34917363]\n",
      " [ 0.          0.          0.         ... -0.00506356 -0.09354757\n",
      "   0.08093339]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.15482497\n",
      "   0.45350487]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.56639404]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T14:46:59.204089Z",
     "start_time": "2025-01-13T14:46:59.191933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Comparing the values of the correlation matrix to the indices of the ROIs\n",
    "for i, j in zip(*indices):\n",
    "    #Iterate only through the first value of each row in the upper triangle of the correlation matrix\n",
    "    if i > 3:\n",
    "        break\n",
    "    if j > 5:\n",
    "        continue\n",
    "    print(f'i: {i}, j: {j}')\n",
    "    fc = corrmat[i, j]\n",
    "    #ROI indexing also starts at 0.\n",
    "    roi_i = i\n",
    "    roi_j = j \n",
    "    print(f\"The functional connectivity between {labels[roi_i][1]} and {labels[roi_j][1]} for subject {subject_idx} during FUS is {fc:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, j: 1\n",
      "The functional connectivity between Retrocalcarine cortex RH and Superior longitudinal fasciculus II mid-posterior RH for subject 0 during FUS is 0.393\n",
      "i: 0, j: 2\n",
      "The functional connectivity between Retrocalcarine cortex RH and Arcuate fasciculus mid-anterior RH for subject 0 during FUS is 0.629\n",
      "i: 0, j: 3\n",
      "The functional connectivity between Retrocalcarine cortex RH and Cerebrospinal fluid (between middle frontal gyrus anterior and skull) for subject 0 during FUS is 0.077\n",
      "i: 0, j: 4\n",
      "The functional connectivity between Retrocalcarine cortex RH and Precentral sulcus mid-inferior RH for subject 0 during FUS is 0.318\n",
      "i: 0, j: 5\n",
      "The functional connectivity between Retrocalcarine cortex RH and Putamen inferior RH for subject 0 during FUS is -0.135\n",
      "i: 1, j: 2\n",
      "The functional connectivity between Superior longitudinal fasciculus II mid-posterior RH and Arcuate fasciculus mid-anterior RH for subject 0 during FUS is 0.214\n",
      "i: 1, j: 3\n",
      "The functional connectivity between Superior longitudinal fasciculus II mid-posterior RH and Cerebrospinal fluid (between middle frontal gyrus anterior and skull) for subject 0 during FUS is 0.096\n",
      "i: 1, j: 4\n",
      "The functional connectivity between Superior longitudinal fasciculus II mid-posterior RH and Precentral sulcus mid-inferior RH for subject 0 during FUS is 0.056\n",
      "i: 1, j: 5\n",
      "The functional connectivity between Superior longitudinal fasciculus II mid-posterior RH and Putamen inferior RH for subject 0 during FUS is 0.240\n",
      "i: 2, j: 3\n",
      "The functional connectivity between Arcuate fasciculus mid-anterior RH and Cerebrospinal fluid (between middle frontal gyrus anterior and skull) for subject 0 during FUS is 0.248\n",
      "i: 2, j: 4\n",
      "The functional connectivity between Arcuate fasciculus mid-anterior RH and Precentral sulcus mid-inferior RH for subject 0 during FUS is 0.231\n",
      "i: 2, j: 5\n",
      "The functional connectivity between Arcuate fasciculus mid-anterior RH and Putamen inferior RH for subject 0 during FUS is 0.026\n",
      "i: 3, j: 4\n",
      "The functional connectivity between Cerebrospinal fluid (between middle frontal gyrus anterior and skull) and Precentral sulcus mid-inferior RH for subject 0 during FUS is 0.516\n",
      "i: 3, j: 5\n",
      "The functional connectivity between Cerebrospinal fluid (between middle frontal gyrus anterior and skull) and Putamen inferior RH for subject 0 during FUS is 0.085\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:32:07.304125Z",
     "start_time": "2025-01-13T15:29:35.990309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "time_segment = {'pre': idx_pre, 'fus': idx_fus, 'post': idx_post}\n",
    "\n",
    "for subject_idx in range(16):\n",
    "\n",
    "    #Iterate through the active time segments\n",
    "    \n",
    "    for name, time in time_segment.items():\n",
    "        bold = bold_3d_active[subject_idx, time, :]\n",
    "        corrmat = np.corrcoef(bold.T)\n",
    "        corrmat = np.triu(corrmat, 1)\n",
    "        indices = np.triu_indices(corrmat.shape[0], 1)\n",
    "        for i, j in zip(*indices):\n",
    "            fc = corrmat[i, j]\n",
    "            data.append([fc, labels[i][1], labels[j][1], subject_idx, name, 'active'])\n",
    "            \n",
    "    #Iterate through the sham time segments    \n",
    "    \n",
    "    for name, time in time_segment.items():    \n",
    "        bold = bold_3d_sham[subject_idx, time, :]\n",
    "        corrmat = np.corrcoef(bold.T)\n",
    "        corrmat = np.triu(corrmat, 1)\n",
    "        indices = np.triu_indices(corrmat.shape[0], 1)\n",
    "        for i, j in zip(*indices):\n",
    "            fc = corrmat[i, j]\n",
    "            data.append([fc, labels[i][1], labels[j][1], subject_idx, name, 'sham'])\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['fc', 'roi1', 'roi2', 'subject', 'time_window', 'condition'])\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T15:35:12.659223Z",
     "start_time": "2025-01-13T15:35:12.655906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "(50282496, 6)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "df.head(10)\n",
    "#\n",
    "df.to_pickle('../data/precomputed/df_fc.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Your task is to fill out this dataframe for all ROI pairs, subjects, conditions, and time windows"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"The functional connectivity between {labels[roi1][1]} and {labels[roi2][1]} for subject {subject_idx} during FUS is {fc:.3f}\")\n",
    "\n",
    "row = pd.DataFrame({'fc': [fc], 'roi1': [roi1], 'roi2': [roi2], 'subject': [subject_idx], 'time_window': ['pre'], 'condition': ['active']})\n",
    "\n",
    "# add a row to df\n",
    "df = pd.concat((df, row), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
