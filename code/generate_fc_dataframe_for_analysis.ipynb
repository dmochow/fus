{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 01.09.2025\n",
    "### Task description for Emily: creating master dataframe for BOLD functional connectivity analysis"
   ]
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:43.997207Z",
     "start_time": "2025-01-09T18:32:43.994556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from nilearn import input_data, datasets\n",
    "import os\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:47.645732Z",
     "start_time": "2025-01-09T18:32:47.643051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## If this is set to true, then the notebook will attempt to generate a giant data structure containing\n",
    "## all the time series for all the subjects and conditions and voxels. This is a very large data structure\n",
    "generate_time_series = False\n",
    "\n",
    "# data_root is only used if generate_time_series is set to True\n",
    "data_root = '/Users/jacekdmochowski/PROJECTS/fus/data/resampled_bold_flywheel/'\n",
    "\n",
    "# if you change these, you straight trippin\n",
    "idx_pre = range(60,300) # we start at 60 instead of 0 because of some strange artifact at the beginning of the time series\n",
    "idx_fus = range(300,600)\n",
    "idx_post = range(600,900)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:49.738168Z",
     "start_time": "2025-01-09T18:32:49.727495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load DiFuMo atlas\n",
    "difumo = datasets.fetch_atlas_difumo(dimension=1024)\n",
    "labels = difumo.labels  # List of 1024 anatomical labels\n",
    "atlas_img = nib.load(difumo.maps)\n",
    "print(labels[:3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Retrocalcarine cortex RH', 'VisCent', 'VisCent', 0.44814054, 0.53647558, 1.53973010e-02)\n",
      " (2, 'Superior longitudinal fasciculus II mid-posterior RH', 'No network found', 'No network found', 0.01732641, 0.98266104, 2.36605469e-05)\n",
      " (3, 'Arcuate fasciculus mid-anterior RH', 'DorsAttnB', 'ContA', 0.50291488, 0.47371745, 2.33761400e-02)]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:52.413644Z",
     "start_time": "2025-01-09T18:32:52.410314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_folders(path):\n",
    "    \"\"\"Gets all folders within a specified path.\"\"\"\n",
    "    folders = []\n",
    "    for entry in os.scandir(path):\n",
    "        if entry.is_dir():\n",
    "            folders.append(entry.name)\n",
    "    return folders"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:53.554297Z",
     "start_time": "2025-01-09T18:32:53.548582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_prepare_data(bold_files, confounds_files, difumo_atlas):\n",
    "    \"\"\"\n",
    "    Load and prepare BOLD data using the DiFuMo probabilistic atlas\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    bold_files : list of str\n",
    "        Paths to preprocessed BOLD data for each subject/session\n",
    "    confounds_files : list of str\n",
    "        Paths to confound regressors from fMRIprep\n",
    "    difumo_atlas : str or NiftiImage\n",
    "        Path to DiFuMo probabilistic atlas or loaded atlas image\n",
    "    target_roi_indices : list of int\n",
    "        Indices of ROIs in target region (subgenual ACC)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    time_series_dict : dict\n",
    "        Dictionary containing cleaned time series for each subject/condition\n",
    "    \"\"\"\n",
    "    # Use NiftiMapsMasker instead of NiftiLabelsMasker for probabilistic atlas\n",
    "    masker = input_data.NiftiMapsMasker(\n",
    "        maps_img=difumo_atlas,\n",
    "        standardize=True,\n",
    "        detrend=False,\n",
    "        low_pass=0.1,\n",
    "        high_pass=0.01,\n",
    "        t_r=1.0,\n",
    "        memory='nilearn_cache',  # Cache computations\n",
    "        memory_level=1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    time_series_dict = {\n",
    "        'active': [],\n",
    "        'sham': []\n",
    "    }\n",
    "\n",
    "    for bold_file, confound_file in zip(bold_files, confounds_files):\n",
    "        # Load confounds\n",
    "        confounds = pd.read_csv(confound_file, sep='\\t')\n",
    "\n",
    "        # Select specific confound regressors\n",
    "        selected_confounds = pd.concat([\n",
    "            # Motion parameters and their derivatives/quadratic terms\n",
    "            #confounds.filter(regex='^(trans|rot)_(x|y|z)($|_derivative1$|_power2$)'),\n",
    "            confounds.filter(regex='^(trans|rot)_(x|y|z)($|_derivative1$)'),\n",
    "\n",
    "            # CompCor components\n",
    "            #confounds.filter(regex='^[at]_comp_cor_\\d+'),\n",
    "\n",
    "            # Global signals\n",
    "            #confounds[['csf', 'white_matter', 'global_signal']],\n",
    "\n",
    "            # Motion outliers\n",
    "            #confounds.filter(regex='^motion_outlier'),\n",
    "\n",
    "            # Edge/crown signals\n",
    "            #confounds.filter(regex='^edge_')\n",
    "        ], axis=1)\n",
    "\n",
    "        # remove any columns in selected_confounds that have nans\n",
    "        selected_confounds = selected_confounds.dropna(axis=1)\n",
    "\n",
    "        # Extract time series with confound regression\n",
    "        # This will now return time series for each probabilistic component\n",
    "        time_series = masker.fit_transform(bold_file, confounds=selected_confounds)\n",
    "\n",
    "        # Sort into conditions\n",
    "        if 'ACTIVE' in bold_file:\n",
    "            time_series_dict['active'].append(time_series)\n",
    "        else:\n",
    "            time_series_dict['sham'].append(time_series)\n",
    "\n",
    "    return time_series_dict"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:54.391163Z",
     "start_time": "2025-01-09T18:32:54.386433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_difumo_atlas(atlas_path):\n",
    "    \"\"\"\n",
    "    Load DiFuMo atlas and verify its dimensions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    atlas_path : str\n",
    "        Path to the DiFuMo atlas file\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    atlas_img : Nifti1Image\n",
    "        Loaded atlas image\n",
    "    \"\"\"\n",
    "    from nilearn import image\n",
    "\n",
    "    atlas_img = image.load_img(atlas_path)\n",
    "\n",
    "    # Verify this is a 4D image with 1024 components\n",
    "    if atlas_img.ndim != 4:\n",
    "        raise ValueError(\"Expected 4D atlas image\")\n",
    "    if atlas_img.shape[-1] != 1024:\n",
    "        raise ValueError(f\"Expected 1024 components, got {atlas_img.shape[-1]}\")\n",
    "\n",
    "    return atlas_img"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:55.452292Z",
     "start_time": "2025-01-09T18:32:55.446758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if generate_time_series:\n",
    "    ## Generate a list of all available bold records from both ACTIVE and SHAM sessions\n",
    "    \n",
    "    # list all folders in data_root\n",
    "    folders = [f for f in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, f))]\n",
    "    bold_files = []\n",
    "    confounds_files = []\n",
    "    for folder in folders:\n",
    "        # find file in output_folder that contains 'preproc_bold_resampled'\n",
    "        output_folder = os.listdir(os.path.join(os.path.join(data_root,folder),'output'))\n",
    "        for file in output_folder:\n",
    "            if 'preproc_bold_resampled' in file:\n",
    "                bold_files.append(os.path.join(os.path.join(data_root,folder),'output',file))\n",
    "    \n",
    "        # confounds timeseries\n",
    "        input_folder=os.path.join(os.path.join(data_root,folder),'input')\n",
    "        tmp=get_folders(os.path.join(os.path.join(data_root,folder),'input'))[0]\n",
    "        tmp2=[x for x in get_folders(os.path.join(input_folder,tmp)) if 'sub-' in x]\n",
    "        tmp3=os.path.join(os.path.join(input_folder,tmp),tmp2[0])\n",
    "        tmp4=[os.path.join(tmp3,x) for x in os.listdir(tmp3) if 'ses-' in x][0]\n",
    "        tmp5=[os.path.join(tmp4,x) for x in os.listdir(tmp4) if 'func' in x][0]\n",
    "        confounds_files.append([os.path.join(tmp5,x) for x in os.listdir(tmp5) if 'confounds_timeseries.tsv' in x][0])\n",
    "    \n",
    "    print(f\"Found {len(bold_files)} bold files\")\n",
    "    print(f\"Found {len(confounds_files)} confounds files\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:56.487598Z",
     "start_time": "2025-01-09T18:32:56.483919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if generate_time_series:\n",
    "    path_to_difumo = '/Users/jacekdmochowski/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_atlas-DiFuMo_desc-1024dimensions_probseg.nii.gz'\n",
    "    try:\n",
    "        difumo_atlas = load_difumo_atlas(path_to_difumo)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error loading DiFuMo atlas: {e}\")\n",
    "        print(\"Attempting to download from TemplateFlow\")\n",
    "        if path_to_difumo is None:\n",
    "            path_to_difumo = api.get('MNI152NLin2009cAsym', atlas=\"DiFuMo\", desc=\"1024dimensions\", resolution=2, suffix=\"probseg\", extension=\"nii.gz\")\n",
    "        difumo_atlas = nib.load(path_to_difumo)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T18:32:58.230891Z",
     "start_time": "2025-01-09T18:32:58.186893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if generate_time_series:\n",
    "    time_series = load_and_prepare_data(bold_files, confounds_files, difumo_atlas)\n",
    "    with open('../data/precomputed/difumo_time_series.pkl', 'wb') as f:\n",
    "        pickle.dump(time_series, f)\n",
    "else:\n",
    "    with open('../data/precomputed/difumo_time_series.pkl', 'rb') as f:\n",
    "        time_series = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Let's take a look at the data, shall we ?!  Yeeaaahhh"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T18:33:12.627353Z",
     "start_time": "2025-01-09T18:33:12.623327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(time_series.keys())\n",
    "print(type(time_series['active']),len(time_series['active']))\n",
    "print(time_series['active'][0].shape) # 900 TRs, 1024 brain regions, yeaaaah"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['active', 'sham'])\n",
      "<class 'list'> 16\n",
      "(900, 1024)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T18:33:16.574181Z",
     "start_time": "2025-01-09T18:33:16.557449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bold_3d_active = np.array(time_series['active'])\n",
    "bold_3d_sham = np.array(time_series['sham'])\n",
    "print(bold_3d_active.shape, bold_3d_sham.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 900, 1024) (16, 900, 1024)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize pandas dataframe that will store all functional connectivity values"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T18:33:26.017125Z",
     "start_time": "2025-01-09T18:33:26.012727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(columns=['fc', 'roi1', 'roi2', 'subject', 'time_window', 'condition'])\n",
    "# subject is a number from 0 to 15\n",
    "# roi is a number from 0 to 1023\n",
    "# only unique pairs of rois should be added (0,1), (0,2), ...  NOT (0,1) and (1,0)\n",
    "# condition is either active or sham\n",
    "# time_window is either pre, fus, or post\n",
    "# fc is a floating point value"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Demonstrate how to compute functional connectivity for one row of the matrix"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T18:34:12.493148Z",
     "start_time": "2025-01-09T18:34:12.486216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subject_idx = 0 # note: we never correlate between subjects\n",
    "roi1 = 0 # zero based indexing!\n",
    "roi2 = 1\n",
    "time_segment = idx_pre\n",
    "\n",
    "this_bold = bold_3d_active[subject_idx,time_segment,:] # the bold of this subject\n",
    "corrmat = np.corrcoef(this_bold[:,[roi1,roi2]].T) # this is called a correlation matrix\n",
    "fc = corrmat[0,1]\n",
    "\n",
    "print(f\"The functional connectivity between {labels[roi1][1]} and {labels[roi2][1]} for subject {subject_idx} during FUS is {fc:.3f}\")\n",
    "\n",
    "row = pd.DataFrame({'fc': [fc], 'roi1': [roi1], 'roi2': [roi2], 'subject': [subject_idx], 'time_window': ['pre'], 'condition': ['active']})\n",
    "\n",
    "# add a row to df\n",
    "df = pd.concat((df, row), axis=0)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The functional connectivity between Retrocalcarine cortex RH and Superior longitudinal fasciculus II mid-posterior RH for subject 0 during FUS is 0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/8jw7l6116kdd4pc549qnnz8r0000gn/T/ipykernel_20731/842304406.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat((df, row), axis=0)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T18:34:14.777762Z",
     "start_time": "2025-01-09T18:34:14.771988Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         fc roi1 roi2 subject time_window condition\n",
       "0  0.392815    0    1       0         pre    active"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fc</th>\n",
       "      <th>roi1</th>\n",
       "      <th>roi2</th>\n",
       "      <th>subject</th>\n",
       "      <th>time_window</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.392815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pre</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Your task is to fill out this dataframe for all ROI pairs, subjects, conditions, and time windows"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
